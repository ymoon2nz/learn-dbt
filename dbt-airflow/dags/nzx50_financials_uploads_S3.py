from airflow.decorators import dag, task
from datetime import datetime, timezone
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
from airflow.providers.amazon.aws.sensors.s3 import S3KeySensor
import os, json
import yfinance as yf, pandas as pd
from pathlib import Path

AWS_S3_CONN_ID = "S3_conn"
S3_BUCKNAME = 'ymoon-au-dbt-fx-raw'
TARGET_PATH = "hist/%s" % datetime.now(timezone.utc).strftime("%Y%m")
LOOKUP_PATH = "lookups"
FNAME_PRE = "stock_financials" 
FNAME_EXT = "json"
NZX50_FNAME = "NZX-50.csv"


def _get_nzx50_symbols():
    filepath = '/tmp/%s/%s/%s' % (S3_BUCKNAME, LOOKUP_PATH, NZX50_FNAME)
    df = pd.read_csv(filepath, usecols=['Profile'])
    return df

@dag(start_date=datetime(2024, 11, 11), schedule='@monthly', catchup=False)
def nzx50_financials_uploads_S3():

    @task
    def download_nzx50_S3():
        print ('Starting nzx50_financials_uploads_S3 - download_nzx50_S3()')
        filepath_name = "/tmp/%s/%s/%s" % (S3_BUCKNAME, LOOKUP_PATH, NZX50_FNAME)
        try:
            filepath = Path(filepath_name)
        except FileNotFoundError:
            print("filename: %s not exists" % filepath_name)
        else:
            print("filename: %s exists" % filepath_name)
            os.remove(filepath_name)
        hook = S3Hook(AWS_S3_CONN_ID)
        local_path = "/tmp/%s/%s/" % (S3_BUCKNAME, LOOKUP_PATH)
        key_filename = "%s/%s" % (LOOKUP_PATH, NZX50_FNAME)
        print ("filename: %s" % key_filename)
        hook.download_file(
            key=key_filename,
            bucket_name=S3_BUCKNAME,
            local_path=local_path,
            preserve_file_name=True,
            use_autogenerated_subdir=False
        )

    @task
    def check_nzx50_if_exists():
        print ('Starting nzx50_financials_uploads_S3')
        df = _get_nzx50_symbols()
        # Loop NZX50 list and check Path
        print ("Checking - /tmp/%s/%s/" % (S3_BUCKNAME, TARGET_PATH))
        if os.path.isdir("/tmp/%s/%s/" % (S3_BUCKNAME, TARGET_PATH)):
            print("directory: /tmp/%s/%s/ Found" % (S3_BUCKNAME, TARGET_PATH))
        else:
            print("/tmp/%s/%s/ Not Exists! Creating..." % (S3_BUCKNAME, TARGET_PATH))
            os.makedirs("/tmp/%s/%s" % (S3_BUCKNAME, TARGET_PATH))
        
        exists_count = 0
        for i, d1 in df.iterrows():
            symbol = "%s.NZ" % d1['Profile']
            filepath_name = "/tmp/%s/%s/%s-%s.%s" % (S3_BUCKNAME, TARGET_PATH, FNAME_PRE, symbol, FNAME_EXT)
            if os.path.isfile(filepath_name):
                print("Filename: %s Already Exists! Today's run already completed?!" % filepath_name)
                raise Exception(filepath_name)
            else:
                # print("Filename: %s not exists" % filepath_name)   
                exists_count += 1
        if exists_count != len(df.index):
            print("File count: %s is Mismatch in Count!" % exists_count)
            raise Exception(filepath_name)
        else:
            print("File count: %s is Matching with Expected (%s)." % (exists_count, len(df.index)))

    @task
    def download_yf_nzx50():
        symbols = _get_nzx50_symbols()
        created_count = 0
        for i, symbol in symbols.iterrows():
            symbol = symbol['Profile']+'.NZ'
            ticker = yf.Ticker(symbol)
            fin = ticker.financials

            # ticker details into one dataframe
            fs = pd.concat([fin])
            fs_json = fs.to_json()
            filename = "%s-%s.%s" % (FNAME_PRE, symbol, FNAME_EXT)
            with open( "/tmp/%s/%s/%s" % (S3_BUCKNAME, TARGET_PATH, filename), 'w') as f:
                f.write('{ "%s": %s }' % (symbol, fs_json))
            #print("Created - /tmp/%s/%s/%s" % (S3_BUCKNAME, TARGET_PATH, filename))
            created_count += 1
        print ("Downloaded in /tmp: %s / %s" % (created_count, len(symbols.index)))

    @task
    def upload_yf_nzx50_S3():
        symbols = _get_nzx50_symbols()
        created_count = 0
        hook = S3Hook(AWS_S3_CONN_ID)
        for i, symbol in symbols.iterrows():
            symbol = symbol['Profile']+'.NZ'
            filename = "%s-%s.%s" % (FNAME_PRE, symbol, FNAME_EXT)
            print ("filename: %s" % filename)
            hook.load_file(
                filename="/tmp/%s/%s/%s" % (S3_BUCKNAME, TARGET_PATH, filename),
                key="%s/%s" % (TARGET_PATH, filename),
                bucket_name=S3_BUCKNAME,
                replace=False
            )
            created_count+=1
        print("Uploaded to S3: %s / %s" % (created_count, len(symbols.index)))
    
    download_nzx50_S3() >> check_nzx50_if_exists() >> download_yf_nzx50() >> upload_yf_nzx50_S3()

nzx50_financials_uploads_S3()