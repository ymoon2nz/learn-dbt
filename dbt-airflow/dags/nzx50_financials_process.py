import os, json
from pathlib import Path
from datetime import datetime, timezone
from airflow.decorators import dag, task
from airflow.operators.postgres_operator import PostgresOperator
from datetime import datetime, timezone
from airflow.providers.amazon.aws.hooks.s3 import S3Hook
import pandas as pd

AWS_S3_CONN_ID = "S3_conn"
S3_BUCKNAME = 'ymoon-au-dbt-fx-raw'
TARGET_PATH = "hist/%s" % datetime.now(timezone.utc).strftime("%Y%m")
LOOKUP_PATH = "lookups"
FNAME_PRE = "stock_financials" 
FNAME_EXT = "json"
NZX50_FNAME = "NZX-50.csv"

def _get_nzx50_symbols():
    filepath = '/tmp/%s/%s/%s' % (S3_BUCKNAME, LOOKUP_PATH, NZX50_FNAME)
    df = pd.read_csv(filepath, usecols=['Profile'])
    return df

def _get_financials_file(symbol):
    filepath = '/tmp/%s/%s/%s-%s.%s' % (S3_BUCKNAME, TARGET_PATH, FNAME_PRE, symbol, FNAME_EXT)
    with open(filepath) as file:
        jsonv = json.load(file)
    return jsonv

@dag(start_date=datetime(2024, 11, 11), schedule='@monthly', catchup=False)
def nzx50_financials_process2_db():

    @task
    def download2_S3_nzx50():
        print ('Starting nzx50_financials_process_db - download_nzx50_S3()')
        filepath_name = "/tmp/%s/%s/%s" % (S3_BUCKNAME, LOOKUP_PATH, NZX50_FNAME)
        try:
            filepath = Path(filepath_name)
        except FileNotFoundError:
            print("filename: %s not exists" % filepath_name)
        else:
            print("filename: %s exists" % filepath_name)
            os.remove(filepath_name)
        hook = S3Hook(AWS_S3_CONN_ID)
        local_path = "/tmp/%s/%s/" % (S3_BUCKNAME, LOOKUP_PATH)
        key_filename = "%s/%s" % (LOOKUP_PATH, NZX50_FNAME)
        print ("filename: %s" % key_filename)
        hook.download_file(
            key=key_filename,
            bucket_name=S3_BUCKNAME,
            local_path=local_path,
            preserve_file_name=True,
            use_autogenerated_subdir=False
        )

    @task()
    def create_stock_details_table():
        print("create_stock_details_table...")
        pgOp = PostgresOperator(
            task_id='create_stock_details_table',
            postgres_conn_id='postgres_conn',
            sql="""
                CREATE TABLE IF NOT EXISTS st.hist_details (
                st_dump_id SERIAL PRIMARY KEY,
                schedule_run TEXT,
                type TEXT,
                info TEXT,
                dump JSON,
                updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                """
        )
        pgOp.execute(dict())
        print("Table: st.hist_details created")

    @task()
    def insert2_db_nzx50():
        print ('Starting nzx50_financials_uploads_S3')
        symbols = _get_nzx50_symbols()
        insert_count = 0
        for i, symbol in symbols.iterrows():
            symbol = "%s.NZ" % symbol['Profile']
            jsonv = _get_financials_file(symbol)
            print(json.dumps(jsonv))
            print(" in-progress... %s" % symbol)
            PostgresOperator(
                task_id='process_nzx50_into_db',
                postgres_conn_id='postgres_conn',
                sql="""
                INSERT INTO st.hist_details (type, schedule_run, info, dump)
                VALUES (%(fname)s, %(run)s, %(info)s, %(json)s)
                """,
                #parameters={ "json" : json.dumps({ "NZDUSD=X" : {} }) }
                parameters={ "fname": FNAME_PRE, "run": TARGET_PATH, "info": symbol, "json": json.dumps(jsonv) }
            ).execute({})
            insert_count+=1
        print("Total Insert: %s!" % str(insert_count))
    
    @task()
    def tag_S3_complete_nzx50():
        print("Starting... tag_S3_complete_nzx50")

    download2_S3_nzx50() >> create_stock_details_table() >> insert2_db_nzx50()

nzx50_financials_process2_db()   